{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastapi import FastAPI\n",
    "# from pydantic import BaseModel\n",
    "\n",
    "# app = FastAPI()\n",
    "\n",
    "# class Item(BaseModel):\n",
    "#     url: str\n",
    "\n",
    "# def test(url):\n",
    "#     #insert AI Model\n",
    "#     return url\n",
    "\n",
    "# @app.post(\"/nlpmodel/\")\n",
    "# async def create_item(item: Item):\n",
    "#     return test(item.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "text=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PYTHON\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = 'D:/Tesseract-OCR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item(BaseModel):\n",
    "    url: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeyWords(text):\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 3\n",
    "    deduplication_threshold = 0.9\n",
    "    deduplication_algo = 'seqm'\n",
    "    windowSize = 1\n",
    "    numOfKeywords = 20\n",
    "\n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, dedupFunc=deduplication_algo, windowsSize=windowSize, top=numOfKeywords, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getimgdescptext(filename):\n",
    "    pdf_file = fitz.open(filename)\n",
    "    pdf_images = []\n",
    "    imgdescp=[]\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    nlp.add_pipe('textrank')\n",
    "    for page_ndex in range(len(pdf_file)):\n",
    "        page = pdf_file[page_ndex]\n",
    "        image_list= pdf_file.get_page_images(page_ndex)\n",
    "        if image_list:\n",
    "            # tottext = page.extract_text()\n",
    "            \n",
    "            doc = nlp(page.extract_text())\n",
    "            for sent in doc.sents:\n",
    "                if 'figure' in sent.text.lower():\n",
    "                    imgdescp.append(sent.text)\n",
    "                if 'fig' in sent.text.lower():\n",
    "                    imgdescp.append(sent.text)\n",
    "                \n",
    "    return imgdescp\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImgDescp(filename):\n",
    "    pdf_file = fitz.open(filename)\n",
    "    pdf_image_list=[]\n",
    "    imgdescps=[]\n",
    "\n",
    "    for page_index in range(len(pdf_file)):\n",
    "    \n",
    "        page = pdf_file[page_index]\n",
    "        image_list = pdf_file.get_page_images(page_index)\n",
    "        if image_list:\n",
    "            pdf_image_list.append(image_list)\n",
    "            \n",
    "        for image_index, img in enumerate(pdf_file.get_page_images(page), start=1):\n",
    "            xref = img[0]\n",
    "            pix = fitz.Pixmap(pdf_file,xref)\n",
    "            piximg = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            # piximgarr = np.array(pix)\n",
    "            decp=''\n",
    "            decp=pytesseract.image_to_string(piximg)\n",
    "            imgdescps.append(decp)\n",
    "            \n",
    "            \n",
    "    return imgdescps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getabstract(filereader):\n",
    "    fulltext = []\n",
    "    for i in filereader.pages:\n",
    "        fulltext+= [i.extract_text()]\n",
    "        currpage = i.extract_text().lower()\n",
    "        if 'abstract' in currpage:\n",
    "            abstract = currpage[currpage.find('abstract'):]\n",
    "            # print('abstrat',abstract)\n",
    "            return abstract\n",
    "        if 'a b s t r a c t' in currpage:\n",
    "            abstract = currpage[currpage.find('a b s t r a c t'):]\n",
    "            # print('abstract',abstract)\n",
    "            return abstract\n",
    "    \n",
    "    return ' '.join(fulltext[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsummary(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    nlp.add_pipe('textrank')\n",
    "    doc = nlp(text)\n",
    "    summ1 = list(doc._.textrank.summary())\n",
    "    tostring = lambda sent:sent.text\n",
    "    summary = list(map(tostring,summ1))\n",
    "    summary = ' '.join(summary)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filename):\n",
    "    text=''\n",
    "    # filename=''\n",
    "    file = open(filename,'rb')\n",
    "    filereader = PyPDF2.PdfReader(file)\n",
    "    text = getabstract(filereader)\n",
    "    resp = {'summary':'','keywords':'',\"img_descp\":''}\n",
    "    resp['keywords'] = getKeyWords(text)\n",
    "    resp['summary']= getsummary(text)\n",
    "    resp['img_descp'] = getImgDescp(filename)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(url):\n",
    "    #insert AI Model\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post('/nlpmodel/')\n",
    "async def create_item(item: Item):\n",
    "    return test(item.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting clean-text\n",
      "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
      "Collecting emoji<2.0.0,>=1.0.0\n",
      "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
      "     -------------------------------------- 175.4/175.4 KB 1.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting ftfy<7.0,>=6.0\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "     -------------------------------------- 53.1/53.1 KB 911.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\naras\\appdata\\roaming\\python\\python39\\site-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.5)\n",
      "Using legacy 'setup.py install' for emoji, since package 'wheel' is not installed.\n",
      "Installing collected packages: emoji, ftfy, clean-text\n",
      "  Running setup.py install for emoji: started\n",
      "  Running setup.py install for emoji: finished with status 'done'\n",
      "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'd:\\PYTHON\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Unidecode\n",
      "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
      "     -------------------------------------- 235.9/235.9 KB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: Unidecode\n",
      "Successfully installed Unidecode-1.3.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'd:\\PYTHON\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some input'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cleantext import clean\n",
    "\n",
    "clean(\"some input\",\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=True,                     # lowercase text\n",
    "    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=False,                  # replace all URLs with a special token\n",
    "    no_emails=False,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "    no_numbers=False,               # replace all numbers with a special token\n",
    "    no_digits=False,                # replace all digits with a special token\n",
    "    no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "    no_punct=False,                 # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_phone_number=\"<PHONE>\",\n",
    "    replace_with_number=\"<NUMBER>\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"<CUR>\",\n",
    "    lang=\"en\"                       # set to 'de' for German special handling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zurich'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean('Zürich',fix_unicode=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2aae14933474253bf7e204dfdcd59c9e221c3358c06c5af46c0ae09e251b4f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
